{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-22T09:29:30.441832400Z",
     "start_time": "2023-09-22T09:29:30.375636100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1900"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open('SNN_XGBoost_similarity_scores_trainingSetFive.txt', 'r') as f:\n",
    "    similarity_scoresTrainingSetOne = [float(line.strip()[1:-1]) for line in f.readlines()]\n",
    "\n",
    "\n",
    "\n",
    "len(similarity_scoresTrainingSetOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape from function:     (1140, 2, 51)\n",
      "[0 0 1 ... 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0, 0, 1, ..., 1, 1, 0])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from creatingPairsForTrainingSetOne_SNNXGBoost import trainingSetOne\n",
    "combined_pairs_trainingSetOne, combined_labels_trainingSetOne, combined_pairs_trainingSetOneXGB, combined_team_pairs = trainingSetOne()\n",
    "\n",
    "combined_labels_trainingSetOne"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T09:29:35.878383400Z",
     "start_time": "2023-09-22T09:29:30.391257400Z"
    }
   },
   "id": "581d92cfe351041b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 3, 14, 8, 22, 5, 30, 16, 27, 15, 12, 6, 2, 19, 1, 25, 23, 29, 9, 7]\n",
      "[11, 8, 3, 14, 30, 22, 7, 5, 15, 27, 19, 12, 6, 2, 1, 16, 23, 29, 25, 9]\n",
      "Accuracy: 20.00%\n",
      "NDCG@5: 0.95\n",
      "Mean Average Precision (up to rank 5): 0.79\n",
      "NDCG@10: 0.96\n",
      "Mean Average Precision (up to rank 10): 0.82\n",
      "NDCG@15: 0.96\n",
      "Mean Average Precision (up to rank 15): 0.84\n",
      "NDCG@20: 0.96\n",
      "Mean Average Precision (up to rank 20): 0.87\n"
     ]
    }
   ],
   "source": [
    "import np\n",
    "import pd\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from math import log2\n",
    "\n",
    "#2018/19\n",
    "with open('predicted_rankingsTrainingSetOne.txt', 'r') as f:\n",
    "    predicted_ranks_array = [int(line.strip()) for line in f.readlines()]\n",
    "print(predicted_ranks_array)\n",
    "actual_rankings = [11,\n",
    "8,\n",
    "3,\n",
    "14,\n",
    "30,\n",
    "22,\n",
    "7,\n",
    "5,\n",
    "15,\n",
    "27,\n",
    "19,\n",
    "12,\n",
    "6,\n",
    "2,\n",
    "1,\n",
    "16,\n",
    "23,\n",
    "29,\n",
    "25,\n",
    "9\n",
    "\n",
    "]\n",
    "print(actual_rankings)\n",
    "\n",
    "count_matches = 0\n",
    "for a, p in zip(actual_rankings, predicted_ranks_array):\n",
    "    if a == p:\n",
    "        count_matches += 1\n",
    "\n",
    "accuracy = count_matches / len(actual_rankings)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "relevance_scores = {}\n",
    "for rank, team in enumerate(actual_rankings):\n",
    "    relevance_scores[team] = 19 - rank\n",
    "\n",
    "def dcg_at_k(predicted_ranks, k):\n",
    "    dcg = 0\n",
    "    for idx, team in enumerate(predicted_ranks[:k]):\n",
    "        dcg += (2**relevance_scores[team] - 1) / log2(idx + 2)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(predicted_ranks, k):\n",
    "    best_dcg = dcg_at_k(sorted(actual_rankings, key=lambda x: relevance_scores[x], reverse=True), k)\n",
    "    actual_dcg = dcg_at_k(predicted_ranks, k)\n",
    "    return actual_dcg / best_dcg\n",
    "\n",
    "\n",
    "def compute_relevance(predicted_rankings, actual_rankings):\n",
    "    \"\"\"Compute continuous relevance values based on rank difference.\"\"\"\n",
    "    relevance = []\n",
    "    for predicted_team in predicted_rankings:\n",
    "        predicted_rank = predicted_rankings.index(predicted_team)\n",
    "        actual_rank = actual_rankings.index(predicted_team)\n",
    "        # The relevance is inversely proportional to rank difference\n",
    "        rel = 1 / (abs(predicted_rank - actual_rank) + 1)\n",
    "        relevance.append(rel)\n",
    "    return relevance\n",
    "\n",
    "\n",
    "def compute_true_and_false_positives(predicted_rankings, actual_rankings, k):\n",
    "    \"\"\"Compute True Positives and False Positives up to rank k.\"\"\"\n",
    "    true_positives = 0\n",
    "    for i in range(k):\n",
    "        predicted_team = predicted_rankings[i]\n",
    "        actual_rank = actual_rankings.index(predicted_team)\n",
    "        if actual_rank < k:\n",
    "            true_positives += 1\n",
    "    false_positives = k - true_positives\n",
    "    return true_positives, false_positives\n",
    "\n",
    "def average_precision(predicted_rankings, actual_rankings, k=20):\n",
    "    \"\"\"Compute Average Precision up to rank k.\"\"\"\n",
    "    true_positives, false_positives = compute_true_and_false_positives(predicted_rankings, actual_rankings, k)\n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "def mean_average_precision(predicted_rankings, actual_rankings, k=20):\n",
    "    \"\"\"Compute Mean Average Precision up to rank k.\"\"\"\n",
    "    return sum(average_precision(predicted_rankings, actual_rankings, k=i) for i in range(1, k+1)) / k\n",
    "\n",
    "# Sample rankings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "k = 5\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "\n",
    "k = 10\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "k = 15\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "# Computing mAP\n",
    "k = 20\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T10:20:29.984295100Z",
     "start_time": "2023-10-13T10:20:29.966093700Z"
    }
   },
   "id": "2bff4b4eee02f5c5"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 3, 14, 8, 22, 5, 30, 16, 27, 15, 12, 6, 19, 2, 1, 35, 23, 7, 28, 10]\n",
      "[8, 11, 22, 3, 15, 14, 7, 30, 10, 1, 16, 5, 6, 12, 23, 27, 35, 2, 19, 28]\n",
      "Accuracy: 0.00%\n",
      "NDCG@5: 0.74\n",
      "Mean Average Precision (up to rank 5): 0.48\n",
      "NDCG@10: 0.74\n",
      "Mean Average Precision (up to rank 10): 0.60\n",
      "NDCG@15: 0.74\n",
      "Mean Average Precision (up to rank 15): 0.66\n",
      "NDCG@20: 0.75\n",
      "Mean Average Precision (up to rank 20): 0.72\n"
     ]
    }
   ],
   "source": [
    "import np\n",
    "import pd\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from math import log2\n",
    "\n",
    "#2019/20\n",
    "with open('predicted_rankingsTrainingSetTwo.txt', 'r') as f:\n",
    "    predicted_ranks_array = [int(line.strip()) for line in f.readlines()]\n",
    "print(predicted_ranks_array)\n",
    "actual_rankings = [8,\n",
    "11,\n",
    "22,\n",
    "3,\n",
    "15,\n",
    "14,\n",
    "7,\n",
    "30,\n",
    "10,\n",
    "1,\n",
    "16,\n",
    "5,\n",
    "6,\n",
    "12,\n",
    "23,\n",
    "27,\n",
    "35,\n",
    "2,\n",
    "19,\n",
    "28\n",
    "]\n",
    "print(actual_rankings)\n",
    "\n",
    "count_matches = 0\n",
    "for a, p in zip(actual_rankings, predicted_ranks_array):\n",
    "    if a == p:\n",
    "        count_matches += 1\n",
    "\n",
    "accuracy = count_matches / len(actual_rankings)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "relevance_scores = {}\n",
    "for rank, team in enumerate(actual_rankings):\n",
    "    relevance_scores[team] = 19 - rank\n",
    "\n",
    "def dcg_at_k(predicted_ranks, k):\n",
    "    dcg = 0\n",
    "    for idx, team in enumerate(predicted_ranks[:k]):\n",
    "        dcg += (2**relevance_scores[team] - 1) / log2(idx + 2)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(predicted_ranks, k):\n",
    "    best_dcg = dcg_at_k(sorted(actual_rankings, key=lambda x: relevance_scores[x], reverse=True), k)\n",
    "    actual_dcg = dcg_at_k(predicted_ranks, k)\n",
    "    return actual_dcg / best_dcg\n",
    "\n",
    "\n",
    "def compute_relevance(predicted_rankings, actual_rankings):\n",
    "    \"\"\"Compute continuous relevance values based on rank difference.\"\"\"\n",
    "    relevance = []\n",
    "    for predicted_team in predicted_rankings:\n",
    "        predicted_rank = predicted_rankings.index(predicted_team)\n",
    "        actual_rank = actual_rankings.index(predicted_team)\n",
    "        # The relevance is inversely proportional to rank difference\n",
    "        rel = 1 / (abs(predicted_rank - actual_rank) + 1)\n",
    "        relevance.append(rel)\n",
    "    return relevance\n",
    "\n",
    "\n",
    "def compute_true_and_false_positives(predicted_rankings, actual_rankings, k):\n",
    "    \"\"\"Compute True Positives and False Positives up to rank k.\"\"\"\n",
    "    true_positives = 0\n",
    "    for i in range(k):\n",
    "        predicted_team = predicted_rankings[i]\n",
    "        actual_rank = actual_rankings.index(predicted_team)\n",
    "        if actual_rank < k:\n",
    "            true_positives += 1\n",
    "    false_positives = k - true_positives\n",
    "    return true_positives, false_positives\n",
    "\n",
    "def average_precision(predicted_rankings, actual_rankings, k=20):\n",
    "    \"\"\"Compute Average Precision up to rank k.\"\"\"\n",
    "    true_positives, false_positives = compute_true_and_false_positives(predicted_rankings, actual_rankings, k)\n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "def mean_average_precision(predicted_rankings, actual_rankings, k=20):\n",
    "    \"\"\"Compute Mean Average Precision up to rank k.\"\"\"\n",
    "    return sum(average_precision(predicted_rankings, actual_rankings, k=i) for i in range(1, k+1)) / k\n",
    "\n",
    "# Sample rankings\n",
    "\n",
    "\n",
    "\n",
    "# Computing mAP\n",
    "k = 5\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "\n",
    "k = 10\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "k = 15\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "# Computing mAP\n",
    "k = 20\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T12:27:41.329285500Z",
     "start_time": "2023-10-13T12:27:41.303249900Z"
    }
   },
   "id": "e4e13594db78e8e5"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 3, 8, 14, 22, 30, 5, 15, 16, 27, 12, 6, 1, 21, 7, 23, 35, 10, 25, 18]\n",
      "[11, 22, 8, 3, 15, 27, 14, 30, 18, 5, 35, 6, 7, 12, 16, 23, 1, 25, 21, 10]\n",
      "Accuracy: 20.00%\n",
      "NDCG@5: 0.92\n",
      "Mean Average Precision (up to rank 5): 0.74\n",
      "NDCG@10: 0.93\n",
      "Mean Average Precision (up to rank 10): 0.77\n",
      "NDCG@15: 0.93\n",
      "Mean Average Precision (up to rank 15): 0.78\n",
      "NDCG@20: 0.93\n",
      "Mean Average Precision (up to rank 20): 0.82\n"
     ]
    }
   ],
   "source": [
    "import np\n",
    "import pd\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from math import log2\n",
    "\n",
    "#2020/21\n",
    "with open('predicted_rankingsTrainingSetThree.txt', 'r') as f:\n",
    "    predicted_ranks_array = [int(line.strip()) for line in f.readlines()]\n",
    "print(predicted_ranks_array)\n",
    "actual_rankings = [11,\n",
    "22,\n",
    "8,\n",
    "3,\n",
    "15,\n",
    "27,\n",
    "14,\n",
    "30,\n",
    "18,\n",
    "5,\n",
    "35,\n",
    "6,\n",
    "7,\n",
    "12,\n",
    "16,\n",
    "23,\n",
    "1,\n",
    "25,\n",
    "21,\n",
    "10\n",
    "]\n",
    "print(actual_rankings)\n",
    "\n",
    "count_matches = 0\n",
    "for a, p in zip(actual_rankings, predicted_ranks_array):\n",
    "    if a == p:\n",
    "        count_matches += 1\n",
    "\n",
    "accuracy = count_matches / len(actual_rankings)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "relevance_scores = {}\n",
    "for rank, team in enumerate(actual_rankings):\n",
    "    relevance_scores[team] = 19 - rank\n",
    "\n",
    "def dcg_at_k(predicted_ranks, k):\n",
    "    dcg = 0\n",
    "    for idx, team in enumerate(predicted_ranks[:k]):\n",
    "        dcg += (2**relevance_scores[team] - 1) / log2(idx + 2)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(predicted_ranks, k):\n",
    "    best_dcg = dcg_at_k(sorted(actual_rankings, key=lambda x: relevance_scores[x], reverse=True), k)\n",
    "    actual_dcg = dcg_at_k(predicted_ranks, k)\n",
    "    return actual_dcg / best_dcg\n",
    "\n",
    "\n",
    "def compute_relevance(predicted_rankings, actual_rankings):\n",
    "    \"\"\"Compute continuous relevance values based on rank difference.\"\"\"\n",
    "    relevance = []\n",
    "    for predicted_team in predicted_rankings:\n",
    "        predicted_rank = predicted_rankings.index(predicted_team)\n",
    "        actual_rank = actual_rankings.index(predicted_team)\n",
    "        # The relevance is inversely proportional to rank difference\n",
    "        rel = 1 / (abs(predicted_rank - actual_rank) + 1)\n",
    "        relevance.append(rel)\n",
    "    return relevance\n",
    "\n",
    "\n",
    "def compute_true_and_false_positives(predicted_rankings, actual_rankings, k):\n",
    "    \"\"\"Compute True Positives and False Positives up to rank k.\"\"\"\n",
    "    true_positives = 0\n",
    "    for i in range(k):\n",
    "        predicted_team = predicted_rankings[i]\n",
    "        actual_rank = actual_rankings.index(predicted_team)\n",
    "        if actual_rank < k:\n",
    "            true_positives += 1\n",
    "    false_positives = k - true_positives\n",
    "    return true_positives, false_positives\n",
    "\n",
    "def average_precision(predicted_rankings, actual_rankings, k=20):\n",
    "    \"\"\"Compute Average Precision up to rank k.\"\"\"\n",
    "    true_positives, false_positives = compute_true_and_false_positives(predicted_rankings, actual_rankings, k)\n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "def mean_average_precision(predicted_rankings, actual_rankings, k=20):\n",
    "    \"\"\"Compute Mean Average Precision up to rank k.\"\"\"\n",
    "    return sum(average_precision(predicted_rankings, actual_rankings, k=i) for i in range(1, k+1)) / k\n",
    "\n",
    "# Sample rankings\n",
    "\n",
    "\n",
    "\n",
    "# Computing mAP\n",
    "# Computing mAP\n",
    "k = 5\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "\n",
    "k = 10\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "k = 15\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "# Computing mAP\n",
    "k = 20\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T12:36:43.475286200Z",
     "start_time": "2023-10-13T12:36:43.450463800Z"
    }
   },
   "id": "2bb41c50d82a368c"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 3, 8, 14, 22, 30, 5, 15, 27, 16, 12, 6, 1, 7, 35, 19, 23, 28, 18, 33]\n",
      "[11, 8, 3, 14, 30, 22, 27, 15, 23, 7, 6, 12, 33, 35, 16, 5, 18, 1, 19, 28]\n",
      "Accuracy: 15.00%\n",
      "NDCG@5: 0.97\n",
      "Mean Average Precision (up to rank 5): 0.86\n",
      "NDCG@10: 0.98\n",
      "Mean Average Precision (up to rank 10): 0.87\n",
      "NDCG@15: 0.98\n",
      "Mean Average Precision (up to rank 15): 0.85\n",
      "NDCG@20: 0.98\n",
      "Mean Average Precision (up to rank 20): 0.86\n"
     ]
    }
   ],
   "source": [
    "import np\n",
    "import pd\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from math import log2\n",
    "\n",
    "#2021/22\n",
    "with open('predicted_rankingsTrainingSetFour.txt', 'r') as f:\n",
    "    predicted_ranks_array = [int(line.strip()) for line in f.readlines()]\n",
    "print(predicted_ranks_array)\n",
    "actual_rankings = [11,\n",
    "8,\n",
    "3,\n",
    "14,\n",
    "30,\n",
    "22,\n",
    "27,\n",
    "15,\n",
    "23,\n",
    "7,\n",
    "6,\n",
    "12,\n",
    "33,\n",
    "35,\n",
    "16,\n",
    "5,\n",
    "18,\n",
    "1,\n",
    "19,\n",
    "28\n",
    "\n",
    "]\n",
    "print(actual_rankings)\n",
    "count_matches = 0\n",
    "for a, p in zip(actual_rankings, predicted_ranks_array):\n",
    "    if a == p:\n",
    "        count_matches += 1\n",
    "\n",
    "accuracy = count_matches / len(actual_rankings)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "relevance_scores = {}\n",
    "for rank, team in enumerate(actual_rankings):\n",
    "    relevance_scores[team] = 19 - rank\n",
    "\n",
    "def dcg_at_k(predicted_ranks, k):\n",
    "    dcg = 0\n",
    "    for idx, team in enumerate(predicted_ranks[:k]):\n",
    "        dcg += (2**relevance_scores[team] - 1) / log2(idx + 2)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(predicted_ranks, k):\n",
    "    best_dcg = dcg_at_k(sorted(actual_rankings, key=lambda x: relevance_scores[x], reverse=True), k)\n",
    "    actual_dcg = dcg_at_k(predicted_ranks, k)\n",
    "    return actual_dcg / best_dcg\n",
    "\n",
    "\n",
    "def compute_relevance(predicted_rankings, actual_rankings):\n",
    "    \"\"\"Compute continuous relevance values based on rank difference.\"\"\"\n",
    "    relevance = []\n",
    "    for predicted_team in predicted_rankings:\n",
    "        predicted_rank = predicted_rankings.index(predicted_team)\n",
    "        actual_rank = actual_rankings.index(predicted_team)\n",
    "        # The relevance is inversely proportional to rank difference\n",
    "        rel = 1 / (abs(predicted_rank - actual_rank) + 1)\n",
    "        relevance.append(rel)\n",
    "    return relevance\n",
    "\n",
    "\n",
    "def compute_true_and_false_positives(predicted_rankings, actual_rankings, k):\n",
    "    \"\"\"Compute True Positives and False Positives up to rank k.\"\"\"\n",
    "    true_positives = 0\n",
    "    for i in range(k):\n",
    "        predicted_team = predicted_rankings[i]\n",
    "        actual_rank = actual_rankings.index(predicted_team)\n",
    "        if actual_rank < k:\n",
    "            true_positives += 1\n",
    "    false_positives = k - true_positives\n",
    "    return true_positives, false_positives\n",
    "\n",
    "def average_precision(predicted_rankings, actual_rankings, k=20):\n",
    "    \"\"\"Compute Average Precision up to rank k.\"\"\"\n",
    "    true_positives, false_positives = compute_true_and_false_positives(predicted_rankings, actual_rankings, k)\n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "def mean_average_precision(predicted_rankings, actual_rankings, k=20):\n",
    "    \"\"\"Compute Mean Average Precision up to rank k.\"\"\"\n",
    "    return sum(average_precision(predicted_rankings, actual_rankings, k=i) for i in range(1, k+1)) / k\n",
    "\n",
    "# Sample rankings\n",
    "\n",
    "\n",
    "# Computing mAP\n",
    "k = 5\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "\n",
    "k = 10\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "k = 15\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "# Computing mAP\n",
    "k = 20\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T19:08:04.085775100Z",
     "start_time": "2023-10-13T19:08:04.065131500Z"
    }
   },
   "id": "c20b2a151bd34987"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 3, 8, 14, 22, 30, 15, 27, 5, 16, 12, 6, 7, 35, 23, 2, 18, 25, 33, 32]\n",
      "[11, 30, 22, 6, 8, 23, 35, 14, 33, 25, 12, 3, 7, 27, 2, 32, 5, 15, 18, 16]\n",
      "Accuracy: 15.00%\n",
      "NDCG@5: 0.75\n",
      "Mean Average Precision (up to rank 5): 0.54\n",
      "NDCG@10: 0.85\n",
      "Mean Average Precision (up to rank 10): 0.56\n",
      "NDCG@15: 0.88\n",
      "Mean Average Precision (up to rank 15): 0.61\n",
      "NDCG@20: 0.88\n",
      "Mean Average Precision (up to rank 20): 0.68\n"
     ]
    }
   ],
   "source": [
    "import np\n",
    "import pd\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from math import log2\n",
    "\n",
    "#2022/23\n",
    "with open('predicted_rankingsTrainingSetFive.txt', 'r') as f:\n",
    "    predicted_ranks_array = [int(line.strip()) for line in f.readlines()]\n",
    "print(predicted_ranks_array)\n",
    "actual_rankings = [11,\n",
    "30,\n",
    "22,\n",
    "6,\n",
    "8,\n",
    "23,\n",
    "35,\n",
    "14,\n",
    "33,\n",
    "25,\n",
    "12,\n",
    "3,\n",
    "7,\n",
    "27,\n",
    "2,\n",
    "32,\n",
    "5,\n",
    "15,\n",
    "18,\n",
    "16\n",
    "\n",
    "\n",
    "]\n",
    "print(actual_rankings)\n",
    "count_matches = 0\n",
    "for a, p in zip(actual_rankings, predicted_ranks_array):\n",
    "    if a == p:\n",
    "        count_matches += 1\n",
    "\n",
    "accuracy = count_matches / len(actual_rankings)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "relevance_scores = {}\n",
    "for rank, team in enumerate(actual_rankings):\n",
    "    relevance_scores[team] = 19 - rank\n",
    "\n",
    "def dcg_at_k(predicted_ranks, k):\n",
    "    dcg = 0\n",
    "    for idx, team in enumerate(predicted_ranks[:k]):\n",
    "        dcg += (2**relevance_scores[team] - 1) / log2(idx + 2)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(predicted_ranks, k):\n",
    "    best_dcg = dcg_at_k(sorted(actual_rankings, key=lambda x: relevance_scores[x], reverse=True), k)\n",
    "    actual_dcg = dcg_at_k(predicted_ranks, k)\n",
    "    return actual_dcg / best_dcg\n",
    "\n",
    "\n",
    "def compute_relevance(predicted_rankings, actual_rankings):\n",
    "    \"\"\"Compute continuous relevance values based on rank difference.\"\"\"\n",
    "    relevance = []\n",
    "    for predicted_team in predicted_rankings:\n",
    "        predicted_rank = predicted_rankings.index(predicted_team)\n",
    "        actual_rank = actual_rankings.index(predicted_team)\n",
    "        # The relevance is inversely proportional to rank difference\n",
    "        rel = 1 / (abs(predicted_rank - actual_rank) + 1)\n",
    "        relevance.append(rel)\n",
    "    return relevance\n",
    "\n",
    "\n",
    "def compute_true_and_false_positives(predicted_rankings, actual_rankings, k):\n",
    "    \"\"\"Compute True Positives and False Positives up to rank k.\"\"\"\n",
    "    true_positives = 0\n",
    "    for i in range(k):\n",
    "        predicted_team = predicted_rankings[i]\n",
    "        actual_rank = actual_rankings.index(predicted_team)\n",
    "        if actual_rank < k:\n",
    "            true_positives += 1\n",
    "    false_positives = k - true_positives\n",
    "    return true_positives, false_positives\n",
    "\n",
    "def average_precision(predicted_rankings, actual_rankings, k=20):\n",
    "    \"\"\"Compute Average Precision up to rank k.\"\"\"\n",
    "    true_positives, false_positives = compute_true_and_false_positives(predicted_rankings, actual_rankings, k)\n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "def mean_average_precision(predicted_rankings, actual_rankings, k=20):\n",
    "    \"\"\"Compute Mean Average Precision up to rank k.\"\"\"\n",
    "    return sum(average_precision(predicted_rankings, actual_rankings, k=i) for i in range(1, k+1)) / k\n",
    "\n",
    "# Sample rankings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Computing mAP\n",
    "k = 5\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "\n",
    "k = 10\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "k = 15\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n",
    "# Computing mAP\n",
    "k = 20\n",
    "map_value = mean_average_precision(predicted_ranks_array, actual_rankings, k)\n",
    "# print(f'DCG@{k}: {dcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f'NDCG@{k}: {ndcg_at_k(predicted_ranks_array, k):.2f}')\n",
    "print(f\"Mean Average Precision (up to rank {k}): {map_value:.2f}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T19:52:32.271874500Z",
     "start_time": "2023-10-13T19:52:32.231342100Z"
    }
   },
   "id": "c06e7632a69241a5"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x array from last epoch: (1140, 51)\n",
      "Shape of y array from last epoch: (1140, 51)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 0.32715631, -0.7423234 ,  1.40850246, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.32715631, -0.7423234 ,  1.40850246, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.32715631, -0.7423234 ,  1.40850246, ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [-0.94004244, -0.89293796, -0.71906966, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.94004244, -0.89293796, -0.71906966, ...,  0.        ,\n         0.        ,  0.        ],\n       [-1.42211545, -1.18570447, -1.21497977, ...,  0.        ,\n         0.        ,  0.        ]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_last_epoch = np.loadtxt(f'activations_a_epoch_49.txt')\n",
    "y_last_epoch = np.loadtxt(f'activations_b_epoch_49.txt')\n",
    "print(f\"Shape of x array from last epoch: {x_last_epoch.shape}\")\n",
    "print(f\"Shape of y array from last epoch: {y_last_epoch.shape}\")\n",
    "x_last_epoch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T19:01:14.963218400Z",
     "start_time": "2023-10-11T19:01:14.821842100Z"
    }
   },
   "id": "310dffc701c306ac"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape from function:     (1140, 2, 51)\n",
      "(1140, 102)\n",
      "combined_pairs_trainingSetOne:  (1140, 102)\n",
      "Updated combined_pairs_trainingSetOneXGB shape: (1140, 204)\n",
      "INFO:tensorflow:Reloading Tuner from xgb_tuner\\xgb_tuning\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "[0]\teval-logloss:0.55332\n",
      "[1]\teval-logloss:0.47762\n",
      "[2]\teval-logloss:0.41907\n",
      "[3]\teval-logloss:0.40135\n",
      "[4]\teval-logloss:0.36915\n",
      "[5]\teval-logloss:0.33962\n",
      "[6]\teval-logloss:0.32227\n",
      "[7]\teval-logloss:0.30699\n",
      "[8]\teval-logloss:0.29078\n",
      "[9]\teval-logloss:0.28326\n",
      "[10]\teval-logloss:0.27200\n",
      "[11]\teval-logloss:0.26927\n",
      "[12]\teval-logloss:0.26335\n",
      "[13]\teval-logloss:0.26080\n",
      "[14]\teval-logloss:0.25456\n",
      "[15]\teval-logloss:0.25456\n",
      "[16]\teval-logloss:0.25375\n",
      "[17]\teval-logloss:0.25360\n",
      "[18]\teval-logloss:0.25367\n",
      "[19]\teval-logloss:0.24028\n",
      "[20]\teval-logloss:0.24028\n",
      "[21]\teval-logloss:0.24028\n",
      "[22]\teval-logloss:0.23654\n",
      "[23]\teval-logloss:0.23654\n",
      "[24]\teval-logloss:0.23474\n",
      "[25]\teval-logloss:0.22798\n",
      "[26]\teval-logloss:0.22802\n",
      "[27]\teval-logloss:0.22795\n",
      "[28]\teval-logloss:0.22795\n",
      "[29]\teval-logloss:0.22827\n",
      "[30]\teval-logloss:0.22827\n",
      "[31]\teval-logloss:0.22644\n",
      "[32]\teval-logloss:0.22644\n",
      "[33]\teval-logloss:0.22634\n",
      "[34]\teval-logloss:0.22641\n",
      "[35]\teval-logloss:0.22628\n",
      "[36]\teval-logloss:0.22638\n",
      "[37]\teval-logloss:0.22638\n",
      "[38]\teval-logloss:0.22664\n",
      "[39]\teval-logloss:0.22679\n",
      "[40]\teval-logloss:0.22652\n",
      "[41]\teval-logloss:0.22658\n",
      "[42]\teval-logloss:0.22664\n",
      "[43]\teval-logloss:0.22664\n",
      "[44]\teval-logloss:0.22668\n",
      "[45]\teval-logloss:0.22628\n",
      "[0.12761827 0.02743193 0.58180416 ... 0.9815112  0.8640674  0.3153373 ]\n",
      "Team 3: 90.1542269254569\n",
      "Team 11: 73.93380046449602\n",
      "Team 8: 65.02236416796222\n",
      "Team 14: 56.60415381193161\n",
      "Team 5: 51.091721213422716\n",
      "Team 2: 21.377682376652956\n",
      "Team 22: 21.144235936924815\n",
      "Team 16: 19.23453564196825\n",
      "Team 15: 6.651300709694624\n",
      "Team 6: 6.170533928088844\n",
      "Team 1: 4.729805916314945\n",
      "Team 12: 4.2899338053539395\n",
      "Team 30: 2.4453640021383762\n",
      "Team 7: 0\n",
      "Team 23: 0\n",
      "Team 9: 0\n",
      "Team 29: -15.273616135120392\n",
      "Team 25: -15.401971397921443\n",
      "Team 19: -22.560306074097753\n",
      "Team 27: -27.85529729654081\n",
      "[3, 11, 8, 14, 5, 2, 22, 16, 15, 6, 1, 12, 30, 7, 23, 9, 29, 25, 19, 27]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from keras_tuner import Objective, RandomSearch, HyperModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_preprocessing import preprocess_data\n",
    "from SNN_and_XGBoost.creatingPairsForTrainingSetOne_SNNXGBoost import trainingSetOne\n",
    "\n",
    "combined_pairs_trainingSetOne, combined_labels_trainingSetOne, combined_pairs_trainingSetOneXGB, combined_team_pairs = trainingSetOne()\n",
    "print(\"combined_pairs_trainingSetOne: \", combined_pairs_trainingSetOneXGB.shape)\n",
    "\n",
    "\n",
    "x_last_epoch = np.round(np.loadtxt(f'activations_a_epoch_49.txt'),1)\n",
    "y_last_epoch = np.round(np.loadtxt(f'activations_a_epoch_49.txt'),1)\n",
    "activation_diff = x_last_epoch - y_last_epoch\n",
    "# Split the combined_pairs_trainingSetOneXGB after the 51st feature\n",
    "part1 = combined_pairs_trainingSetOneXGB[:, :51]\n",
    "part2 = combined_pairs_trainingSetOneXGB[:, 51:]\n",
    "\n",
    "# Concatenate the three parts: part1, x_last_epoch, and y_last_epoch\n",
    "new_combined_pairs = np.hstack((part1, x_last_epoch, part2, y_last_epoch))\n",
    "\n",
    "# Replace the original combined_pairs_trainingSetOneXGB with the new concatenated array\n",
    "combined_pairs_trainingSetOneXGB = new_combined_pairs\n",
    "\n",
    "print(\"Updated combined_pairs_trainingSetOneXGB shape:\", combined_pairs_trainingSetOneXGB.shape)\n",
    "\n",
    "combined_pairs_df = pd.DataFrame(combined_pairs_trainingSetOneXGB)\n",
    "pairwise_X = combined_pairs_df\n",
    "\n",
    "pairwise_y = combined_labels_trainingSetOne\n",
    "X_train, X_val, y_train, y_val = train_test_split(pairwise_X, pairwise_y, test_size=0.2, random_state=42)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "class XGBHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        param = {\n",
    "            'max_depth': hp.Int('max_depth', 3, 10, 1),\n",
    "            'eta': hp.Float('eta', 0.01, 0.5, step=0.01),\n",
    "            'subsample': hp.Float('subsample', 0.5, 1),\n",
    "            'colsample_bytree': hp.Float('colsample_bytree', 0.5, 1),\n",
    "            'gamma': hp.Float('gamma', 0, 5),\n",
    "            'min_child_weight': hp.Int('min_child_weight', 1, 10),\n",
    "            'lambda': hp.Float('lambda', 0.01, 1),\n",
    "            'alpha': hp.Float('alpha', 0.01, 1),\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss'\n",
    "        }\n",
    "        return param\n",
    "\n",
    "class XGBTuner(RandomSearch):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        hp = trial.hyperparameters\n",
    "        params = self.hypermodel.build(hp)\n",
    "        evals_result = {}\n",
    "        bst = xgb.train(params, dtrain, evals=[(dval, 'eval')], early_stopping_rounds=10, verbose_eval=False, evals_result=evals_result)\n",
    "        last_eval = evals_result['eval']['logloss'][-1]\n",
    "        self.oracle.update_trial(trial.trial_id, {'val_logloss': last_eval})\n",
    "        self.save_model(trial.trial_id, bst)\n",
    "\n",
    "    def save_model(self, trial_id, model, step=0):\n",
    "        fname = os.path.join(self.get_trial_dir(trial_id), f'model_{step}.xgb')\n",
    "        model.save_model(fname)\n",
    "\n",
    "    def load_model(self, trial_id, step=0):\n",
    "        fname = os.path.join(self.get_trial_dir(trial_id), f'model_{step}.xgb')\n",
    "        model = xgb.Booster()\n",
    "        model.load_model(fname)\n",
    "        return model\n",
    "\n",
    "tuner = XGBTuner(XGBHyperModel(), objective=Objective('val_logloss', direction='min'), max_trials=50, directory='xgb_tuner', project_name='xgb_tuning')\n",
    "tuner.search()\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "best_params = {\n",
    "    'max_depth': best_hp.get('max_depth'),\n",
    "    'eta': best_hp.get('eta'),\n",
    "    'subsample': best_hp.get('subsample'),\n",
    "    'colsample_bytree': best_hp.get('colsample_bytree'),\n",
    "    'gamma': best_hp.get('gamma'),\n",
    "    'min_child_weight': best_hp.get('min_child_weight'),\n",
    "    'lambda': best_hp.get('lambda'),\n",
    "    'alpha': best_hp.get('alpha'),\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "num_round = 60\n",
    "bst_aggregated = xgb.train(best_params, dtrain, num_round, evals=[(dval, 'eval')], early_stopping_rounds=10)\n",
    "bst_aggregated.save_model('XGBoosttrainingSetOne.xgb')\n",
    "\n",
    "def load_best_model(model_path):\n",
    "    bst = xgb.Booster()\n",
    "    bst.load_model(model_path)\n",
    "    return bst\n",
    "\n",
    "def predict_using_train_data(model, train_data):\n",
    "    dtrain_full = xgb.DMatrix(train_data)\n",
    "    predictions = model.predict(dtrain_full)\n",
    "    return predictions\n",
    "\n",
    "bst = load_best_model('XGBoosttrainingSetOne.xgb')\n",
    "predictions_train = predict_using_train_data(bst, pairwise_X)\n",
    "print(predictions_train)\n",
    "\n",
    "\n",
    "\n",
    "actual_rankings = [11, 8, 3, 14, 30, 22, 7, 5, 15, 27, 19, 12, 6, 2, 1, 16, 23, 29, 25, 9]\n",
    "\n",
    "# Assuming combined_team_pairs is an array of tuples where each tuple is (team1, team2)\n",
    "# Extract pairs containing the teams in actual_rankings\n",
    "filtered_pairs = [pair for pair in combined_team_pairs if pair[0] in actual_rankings or pair[1] in actual_rankings]\n",
    "\n",
    "# Convert these pairs to feature differences similar to how you prepared your training data\n",
    "filtered_data = [pairwise_X.iloc[i] for i, pair in enumerate(combined_team_pairs) if pair in filtered_pairs]\n",
    "\n",
    "# Convert to DataFrame and then to DMatrix for prediction\n",
    "filtered_data_df = pd.DataFrame(filtered_data)\n",
    "dtest_filtered = xgb.DMatrix(filtered_data_df)\n",
    "\n",
    "# Predict using the trained model\n",
    "predictions_filtered = bst.predict(dtest_filtered)\n",
    "\n",
    "# Sum predictions for each team based on your logic\n",
    "team_prediction_sums = {team: 0 for team in actual_rankings}\n",
    "for i, pair in enumerate(filtered_pairs):\n",
    "\n",
    "        if pair[0] in actual_rankings:\n",
    "            team_prediction_sums[pair[0]] += predictions_filtered[i]  # Add to team1\n",
    "        if pair[1] in actual_rankings:\n",
    "            team_prediction_sums[pair[1]] -= predictions_filtered[i]  # Subtract from team2\n",
    "\n",
    "\n",
    "\n",
    "# Display the final predictions\n",
    "sorted_teams = sorted(team_prediction_sums.items(), key=lambda x: x[1], reverse=True)\n",
    "for team, prediction in sorted_teams:\n",
    "    print(f\"Team {team}: {prediction}\")\n",
    "\n",
    "sorted_teams = sorted(team_prediction_sums.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_rankings = [team[0] for team in sorted_teams]\n",
    "print(sorted_rankings)\n",
    "with open('predicted_rankingsTrainingSetOne.txt', 'w') as f:\n",
    "    for team in sorted_rankings:\n",
    "        f.write(f\"{team}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T19:21:15.084585400Z",
     "start_time": "2023-10-11T19:21:08.029066200Z"
    }
   },
   "id": "7cf967749d24fb11"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1         2         3         4         5         6    \\\n0     0.327156 -0.742323  1.408502  0.962273  2.385065  3.194213  1.467098   \n1     0.327156 -0.742323  1.408502  0.962273  2.385065  3.194213  1.467098   \n2     0.327156 -0.742323  1.408502  0.962273  2.385065  3.194213  1.467098   \n3     0.327156 -0.742323  1.408502  0.962273  2.385065  3.194213  1.467098   \n4     0.327156 -0.742323  1.408502  0.962273  2.385065  3.194213  1.467098   \n...        ...       ...       ...       ...       ...       ...       ...   \n1135 -0.678046 -0.209816 -1.462935 -0.779378 -0.730901 -1.075412 -0.478884   \n1136 -0.678046 -0.209816 -1.462935 -0.779378 -0.730901 -1.075412 -0.478884   \n1137 -0.940042 -0.892938 -0.719070 -0.832157 -0.897015 -0.586588 -0.884718   \n1138 -0.940042 -0.892938 -0.719070 -0.832157 -0.897015 -0.586588 -0.884718   \n1139 -1.422115 -1.185704 -1.214980 -1.359953 -1.450728 -0.831000 -1.371719   \n\n           7         8         9    ...  194  195  196  197  198  199  200  \\\n0     0.227552 -0.486266  1.178919  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1     0.227552 -0.486266  1.178919  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2     0.227552 -0.486266  1.178919  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3     0.227552 -0.486266  1.178919  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4     0.227552 -0.486266  1.178919  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n1135 -0.656431 -0.031290 -0.606448  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1136 -0.656431 -0.031290 -0.606448  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1137 -0.656431 -1.583259 -0.411762  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1138 -0.656431 -1.583259 -0.411762  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1139 -1.572382  0.010430 -1.248913  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n\n      201  202  203  \n0     0.0  0.0  0.0  \n1     0.0  0.0  0.0  \n2     0.0  0.0  0.0  \n3     0.0  0.0  0.0  \n4     0.0  0.0  0.0  \n...   ...  ...  ...  \n1135  1.0  0.0  0.0  \n1136  1.0  0.0  0.0  \n1137  0.0  0.0  0.0  \n1138  0.0  0.0  0.0  \n1139  0.0  0.0  0.0  \n\n[1140 rows x 204 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>194</th>\n      <th>195</th>\n      <th>196</th>\n      <th>197</th>\n      <th>198</th>\n      <th>199</th>\n      <th>200</th>\n      <th>201</th>\n      <th>202</th>\n      <th>203</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.327156</td>\n      <td>-0.742323</td>\n      <td>1.408502</td>\n      <td>0.962273</td>\n      <td>2.385065</td>\n      <td>3.194213</td>\n      <td>1.467098</td>\n      <td>0.227552</td>\n      <td>-0.486266</td>\n      <td>1.178919</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.327156</td>\n      <td>-0.742323</td>\n      <td>1.408502</td>\n      <td>0.962273</td>\n      <td>2.385065</td>\n      <td>3.194213</td>\n      <td>1.467098</td>\n      <td>0.227552</td>\n      <td>-0.486266</td>\n      <td>1.178919</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.327156</td>\n      <td>-0.742323</td>\n      <td>1.408502</td>\n      <td>0.962273</td>\n      <td>2.385065</td>\n      <td>3.194213</td>\n      <td>1.467098</td>\n      <td>0.227552</td>\n      <td>-0.486266</td>\n      <td>1.178919</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.327156</td>\n      <td>-0.742323</td>\n      <td>1.408502</td>\n      <td>0.962273</td>\n      <td>2.385065</td>\n      <td>3.194213</td>\n      <td>1.467098</td>\n      <td>0.227552</td>\n      <td>-0.486266</td>\n      <td>1.178919</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.327156</td>\n      <td>-0.742323</td>\n      <td>1.408502</td>\n      <td>0.962273</td>\n      <td>2.385065</td>\n      <td>3.194213</td>\n      <td>1.467098</td>\n      <td>0.227552</td>\n      <td>-0.486266</td>\n      <td>1.178919</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1135</th>\n      <td>-0.678046</td>\n      <td>-0.209816</td>\n      <td>-1.462935</td>\n      <td>-0.779378</td>\n      <td>-0.730901</td>\n      <td>-1.075412</td>\n      <td>-0.478884</td>\n      <td>-0.656431</td>\n      <td>-0.031290</td>\n      <td>-0.606448</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1136</th>\n      <td>-0.678046</td>\n      <td>-0.209816</td>\n      <td>-1.462935</td>\n      <td>-0.779378</td>\n      <td>-0.730901</td>\n      <td>-1.075412</td>\n      <td>-0.478884</td>\n      <td>-0.656431</td>\n      <td>-0.031290</td>\n      <td>-0.606448</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1137</th>\n      <td>-0.940042</td>\n      <td>-0.892938</td>\n      <td>-0.719070</td>\n      <td>-0.832157</td>\n      <td>-0.897015</td>\n      <td>-0.586588</td>\n      <td>-0.884718</td>\n      <td>-0.656431</td>\n      <td>-1.583259</td>\n      <td>-0.411762</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1138</th>\n      <td>-0.940042</td>\n      <td>-0.892938</td>\n      <td>-0.719070</td>\n      <td>-0.832157</td>\n      <td>-0.897015</td>\n      <td>-0.586588</td>\n      <td>-0.884718</td>\n      <td>-0.656431</td>\n      <td>-1.583259</td>\n      <td>-0.411762</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1139</th>\n      <td>-1.422115</td>\n      <td>-1.185704</td>\n      <td>-1.214980</td>\n      <td>-1.359953</td>\n      <td>-1.450728</td>\n      <td>-0.831000</td>\n      <td>-1.371719</td>\n      <td>-1.572382</td>\n      <td>0.010430</td>\n      <td>-1.248913</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1140 rows  204 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_pairs_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T18:56:55.153075500Z",
     "start_time": "2023-10-11T18:56:55.044797100Z"
    }
   },
   "id": "20d3851dd82ac85"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape from function:     (1140, 2, 51)\n",
      "(1140, 102)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 0.3271563 , -0.74232339,  1.40850248, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.3271563 , -0.74232339,  1.40850248, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.3271563 , -0.74232339,  1.40850248, ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [-0.94004244, -0.89293794, -0.71906966, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.94004244, -0.89293794, -0.71906966, ...,  0.        ,\n         0.        ,  0.        ],\n       [-1.42211548, -1.18570447, -1.21497977, ...,  0.        ,\n         0.        ,  0.        ]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SNN_and_XGBoost.creatingPairsForTrainingSetOne_SNNXGBoost import trainingSetOne\n",
    "\n",
    "combined_pairs_trainingSetOne, combined_labels_trainingSetOne, combined_pairs_trainingSetOneXGB, combined_team_pairs = trainingSetOne()\n",
    "combined_pairs_trainingSetOneXGB"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T19:00:57.230035700Z",
     "start_time": "2023-10-11T19:00:53.194662400Z"
    }
   },
   "id": "ac3cab499b647ec0"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Me\\AppData\\Local\\Temp\\ipykernel_11772\\3498720739.py:9: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.engine.hypermodel import HyperModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape from function:     (1140, 2, 51)\n",
      "(1140, 102)\n",
      "INFO:tensorflow:Reloading Tuner from siamese_tuning\\siamese_network\\tuner0.json\n",
      "(None, 51)\n",
      "(None, 51)\n",
      "SaveArraysCallback instantiated\n",
      "Training started\n",
      "Starting epoch 0\n",
      "Epoch 1/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 7.7613  Ending epoch 0\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 2s 19ms/step - loss: 7.4404 - val_loss: 5.6970\n",
      "Starting epoch 1\n",
      "Epoch 2/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 6.1781Ending epoch 1\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 5.9747 - val_loss: 5.6296\n",
      "Starting epoch 2\n",
      "Epoch 3/50\n",
      "18/35 [==============>...............] - ETA: 0s - loss: 5.0210Ending epoch 2\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 5.4112 - val_loss: 5.8379\n",
      "Starting epoch 3\n",
      "Epoch 4/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 5.1232Ending epoch 3\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 5.1995 - val_loss: 5.8412\n",
      "Starting epoch 4\n",
      "Epoch 5/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 4.7773Ending epoch 4\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.9728 - val_loss: 5.6750\n",
      "Starting epoch 5\n",
      "Epoch 6/50\n",
      "18/35 [==============>...............] - ETA: 0s - loss: 4.9258Ending epoch 5\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.8594 - val_loss: 5.7223\n",
      "Starting epoch 6\n",
      "Epoch 7/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 4.8218Ending epoch 6\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.7777 - val_loss: 5.5748\n",
      "Starting epoch 7\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - ETA: 0s - loss: 4.6796Ending epoch 7\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 4.6796 - val_loss: 5.5750\n",
      "Starting epoch 8\n",
      "Epoch 9/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 4.4105Ending epoch 8\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.4894 - val_loss: 5.5832\n",
      "Starting epoch 9\n",
      "Epoch 10/50\n",
      "21/35 [=================>............] - ETA: 0s - loss: 4.3695Ending epoch 9\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.4390 - val_loss: 5.4465\n",
      "Starting epoch 10\n",
      "Epoch 11/50\n",
      "25/35 [====================>.........] - ETA: 0s - loss: 4.3161Ending epoch 10\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.3223 - val_loss: 5.2394\n",
      "Starting epoch 11\n",
      "Epoch 12/50\n",
      "21/35 [=================>............] - ETA: 0s - loss: 4.2347Ending epoch 11\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.2346 - val_loss: 5.3655\n",
      "Starting epoch 12\n",
      "Epoch 13/50\n",
      "21/35 [=================>............] - ETA: 0s - loss: 4.2914Ending epoch 12\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.1673 - val_loss: 5.2854\n",
      "Starting epoch 13\n",
      "Epoch 14/50\n",
      "34/35 [============================>.] - ETA: 0s - loss: 4.0360Ending epoch 13\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 4.0404 - val_loss: 5.4521\n",
      "Starting epoch 14\n",
      "Epoch 15/50\n",
      "21/35 [=================>............] - ETA: 0s - loss: 3.8504Ending epoch 14\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.0488 - val_loss: 5.3525\n",
      "Starting epoch 15\n",
      "Epoch 16/50\n",
      "18/35 [==============>...............] - ETA: 0s - loss: 4.1417Ending epoch 15\n",
      "36/36 [==============================] - 0s 906us/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.0902 - val_loss: 5.3090\n",
      "Starting epoch 16\n",
      "Epoch 17/50\n",
      "18/35 [==============>...............] - ETA: 0s - loss: 3.9755Ending epoch 16\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 4.0846 - val_loss: 5.2499\n",
      "Starting epoch 17\n",
      "Epoch 18/50\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 4.0494Ending epoch 17\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 4.0443 - val_loss: 5.1821\n",
      "Starting epoch 18\n",
      "Epoch 19/50\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 3.9753Ending epoch 18\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.9919 - val_loss: 5.3067\n",
      "Starting epoch 19\n",
      "Epoch 20/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 4.0213Ending epoch 19\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.9520 - val_loss: 5.3190\n",
      "Starting epoch 20\n",
      "Epoch 21/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 4.0308Ending epoch 20\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 4.0238 - val_loss: 5.3579\n",
      "Starting epoch 21\n",
      "Epoch 22/50\n",
      "22/35 [=================>............] - ETA: 0s - loss: 3.8299Ending epoch 21\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.9736 - val_loss: 5.3857\n",
      "Starting epoch 22\n",
      "Epoch 23/50\n",
      "22/35 [=================>............] - ETA: 0s - loss: 3.9742Ending epoch 22\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 4.0699 - val_loss: 5.3603\n",
      "Starting epoch 23\n",
      "Epoch 24/50\n",
      "21/35 [=================>............] - ETA: 0s - loss: 3.9167Ending epoch 23\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.9915 - val_loss: 5.3338\n",
      "Starting epoch 24\n",
      "Epoch 25/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 3.8668Ending epoch 24\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.8915 - val_loss: 5.1970\n",
      "Starting epoch 25\n",
      "Epoch 26/50\n",
      "18/35 [==============>...............] - ETA: 0s - loss: 3.8241Ending epoch 25\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.9201 - val_loss: 5.4912\n",
      "Starting epoch 26\n",
      "Epoch 27/50\n",
      "34/35 [============================>.] - ETA: 0s - loss: 3.9179Ending epoch 26\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.9046 - val_loss: 5.4244\n",
      "Starting epoch 27\n",
      "Epoch 28/50\n",
      "21/35 [=================>............] - ETA: 0s - loss: 3.8899Ending epoch 27\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.8555 - val_loss: 5.4257\n",
      "Starting epoch 28\n",
      "Epoch 29/50\n",
      "21/35 [=================>............] - ETA: 0s - loss: 3.6999Ending epoch 28\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.7883 - val_loss: 5.2376\n",
      "Starting epoch 29\n",
      "Epoch 30/50\n",
      "21/35 [=================>............] - ETA: 0s - loss: 3.8447Ending epoch 29\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.8309 - val_loss: 5.4039\n",
      "Starting epoch 30\n",
      "Epoch 31/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 3.8809Ending epoch 30\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.8960 - val_loss: 5.3441\n",
      "Starting epoch 31\n",
      "Epoch 32/50\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 3.8768Ending epoch 31\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.8782 - val_loss: 5.3707\n",
      "Starting epoch 32\n",
      "Epoch 33/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 3.9740Ending epoch 32\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.8574 - val_loss: 5.5722\n",
      "Starting epoch 33\n",
      "Epoch 34/50\n",
      "20/35 [================>.............] - ETA: 0s - loss: 3.6550Ending epoch 33\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.7432 - val_loss: 5.5157\n",
      "Starting epoch 34\n",
      "Epoch 35/50\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 3.7299Ending epoch 34\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 3.7722 - val_loss: 5.4332\n",
      "Starting epoch 35\n",
      "Epoch 36/50\n",
      "20/35 [================>.............] - ETA: 0s - loss: 3.7560Ending epoch 35\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.7581 - val_loss: 5.3484\n",
      "Starting epoch 36\n",
      "Epoch 37/50\n",
      "31/35 [=========================>....] - ETA: 0s - loss: 3.8133Ending epoch 36\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.8394 - val_loss: 5.5109\n",
      "Starting epoch 37\n",
      "Epoch 38/50\n",
      "34/35 [============================>.] - ETA: 0s - loss: 3.8833Ending epoch 37\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.8756 - val_loss: 5.4487\n",
      "Starting epoch 38\n",
      "Epoch 39/50\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 3.7608Ending epoch 38\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.7612 - val_loss: 5.4854\n",
      "Starting epoch 39\n",
      "Epoch 40/50\n",
      "21/35 [=================>............] - ETA: 0s - loss: 3.7070Ending epoch 39\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.8031 - val_loss: 5.4406\n",
      "Starting epoch 40\n",
      "Epoch 41/50\n",
      "25/35 [====================>.........] - ETA: 1s - loss: 3.6734Ending epoch 40\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 3s 98ms/step - loss: 3.8219 - val_loss: 5.4212\n",
      "Starting epoch 41\n",
      "Epoch 42/50\n",
      "18/35 [==============>...............] - ETA: 0s - loss: 3.5781Ending epoch 41\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.7523 - val_loss: 5.3214\n",
      "Starting epoch 42\n",
      "Epoch 43/50\n",
      "34/35 [============================>.] - ETA: 0s - loss: 3.7926Ending epoch 42\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 3.7963 - val_loss: 5.3319\n",
      "Starting epoch 43\n",
      "Epoch 44/50\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 3.7861Ending epoch 43\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.7421 - val_loss: 5.3209\n",
      "Starting epoch 44\n",
      "Epoch 45/50\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 3.6934Ending epoch 44\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 3.7167 - val_loss: 5.2611\n",
      "Starting epoch 45\n",
      "Epoch 46/50\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 3.7780Ending epoch 45\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.7414 - val_loss: 5.4346\n",
      "Starting epoch 46\n",
      "Epoch 47/50\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 3.6538Ending epoch 46\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.7903 - val_loss: 5.3078\n",
      "Starting epoch 47\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - ETA: 0s - loss: 3.7445Ending epoch 47\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 3.7445 - val_loss: 5.3630\n",
      "Starting epoch 48\n",
      "Epoch 49/50\n",
      "19/35 [===============>..............] - ETA: 0s - loss: 3.8172Ending epoch 48\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.7264 - val_loss: 5.5318\n",
      "Starting epoch 49\n",
      "Epoch 50/50\n",
      "34/35 [============================>.] - ETA: 0s - loss: 3.6913Ending epoch 49\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.6869 - val_loss: 5.4341\n",
      "Training ended\n",
      "(None, 51)\n",
      "(None, 51)\n",
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow.keras.backend as K\n",
    "from SNN_and_XGBoost.creatingPairsForTrainingSetOne_SNNXGBoost import trainingSetOne\n",
    "from kerastuner.engine.hypermodel import HyperModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 5\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "class SaveArraysCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, activation_model, data):\n",
    "        super(SaveArraysCallback, self).__init__()\n",
    "        self.activation_model = activation_model\n",
    "        self.data = data\n",
    "        print(\"SaveArraysCallback instantiated\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Ending epoch {epoch}\")\n",
    "        activations_a, activations_b = self.activation_model.predict(self.data)\n",
    "        np.savetxt(f'activations_a_epoch_{epoch}.txt', activations_a)\n",
    "        np.savetxt(f'activations_b_epoch_{epoch}.txt', activations_b)\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"Training started\")\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"Training ended\")\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"Starting epoch {epoch}\")\n",
    "class SiameseHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        input = Input(shape=self.input_shape)\n",
    "        x = Flatten()(input)\n",
    "        for _ in range(hp.Int('num_layers', 1, 3)):\n",
    "            x = Dense(units=hp.Int('units', min_value=10, max_value=70, step=3), activation='relu')(x)\n",
    "            x = Dropout(rate=hp.Float('dropout', min_value=0.005, max_value=0.3, step=0.01))(x)\n",
    "        x = Dense(5, activation='relu')(x)\n",
    "        base_network = Model(inputs=input, outputs=x)\n",
    "\n",
    "        input_a = Input(shape=self.input_shape)\n",
    "        print(input_a.shape)\n",
    "\n",
    "        input_b = Input(shape=self.input_shape)\n",
    "        print(input_b.shape)\n",
    "        processed_a = base_network(input_a)\n",
    "\n",
    "        processed_b = base_network(input_b)\n",
    "        distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "        # distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([input_a, input_b])\n",
    "\n",
    "        model = Model([input_a, input_b], distance)\n",
    "        model.compile(loss=contrastive_loss,\n",
    "                      optimizer=RMSprop(learning_rate=hp.Choice('learning_rate', [1e-1, 1e-2, 1e-3, 1e-4])))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def activation_model(self, base_network):\n",
    "        input_a = Input(shape=self.input_shape)\n",
    "        input_b = Input(shape=self.input_shape)\n",
    "        processed_a = base_network(input_a)\n",
    "        processed_b = base_network(input_b)\n",
    "        return Model([input_a, input_b], [processed_a, processed_b])\n",
    "\n",
    "\n",
    "combined_pairs_trainingSetOne, combined_labels_trainingSetOne, _, _ = trainingSetOne()\n",
    "combined_labels_trainingSetOne = np.array(combined_labels_trainingSetOne, dtype=np.float32)\n",
    "\n",
    "input_shape = combined_pairs_trainingSetOne.shape[-1]\n",
    "hypermodel = SiameseHyperModel(input_shape)\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='siamese_tuning',\n",
    "    project_name='siamese_network'\n",
    ")\n",
    "\n",
    "(train_pairs, val_pairs, train_labels, val_labels) = train_test_split(\n",
    "    combined_pairs_trainingSetOne,\n",
    "    combined_labels_trainingSetOne,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "model = hypermodel.build(best_hp)\n",
    "activation_model_instance = hypermodel.activation_model(model.layers[-3])\n",
    "\n",
    "model.fit(\n",
    "    [train_pairs[:, 0], train_pairs[:, 1]], train_labels,\n",
    "    validation_data=([val_pairs[:, 0], val_pairs[:, 1]], val_labels),\n",
    "    batch_size=30, epochs=50,\n",
    "    callbacks=[SaveArraysCallback(activation_model=activation_model_instance, data=[combined_pairs_trainingSetOne[:, 0], combined_pairs_trainingSetOne[:, 1]])]\n",
    ")\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.save('best_siamese_model_forXGBoost_trainingSetOne.keras')\n",
    "activations_a_before_training, activations_b_before_training = activation_model_instance.predict([combined_pairs_trainingSetOne[:, 0], combined_pairs_trainingSetOne[:, 1]])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T19:14:50.556556300Z",
     "start_time": "2023-10-11T19:14:17.928948Z"
    }
   },
   "id": "bdc3fe35e99f7e79"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.3271563 , -0.7423234 ,  1.4085025 , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.3271563 , -0.7423234 ,  1.4085025 , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.3271563 , -0.7423234 ,  1.4085025 , ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [-0.94004244, -0.89293796, -0.71906966, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.94004244, -0.89293796, -0.71906966, ...,  0.        ,\n         0.        ,  0.        ],\n       [-1.4221154 , -1.1857045 , -1.2149798 , ...,  0.        ,\n         0.        ,  0.        ]], dtype=float32)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations_a_before_training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T19:14:56.781491200Z",
     "start_time": "2023-10-11T19:14:56.740896200Z"
    }
   },
   "id": "a8387d156ee5bc03"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 51)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)        [(None, 51)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        multiple                     0         ['input_4[0][0]',             \n",
      "                                                                     'input_5[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 0 (0.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "activation_model_instance.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T19:15:44.645106Z",
     "start_time": "2023-10-11T19:15:44.597110500Z"
    }
   },
   "id": "f5780b1d207e3643"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "activations_a_after_training, activations_b_after_training = activation_model_instance.predict([combined_pairs_trainingSetOne[:, 0], combined_pairs_trainingSetOne[:, 1]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T19:16:08.995651200Z",
     "start_time": "2023-10-11T19:16:08.725852300Z"
    }
   },
   "id": "e24b7618f8a2859f"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.3271563 , -0.7423234 ,  1.4085025 , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.3271563 , -0.7423234 ,  1.4085025 , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.3271563 , -0.7423234 ,  1.4085025 , ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [-0.94004244, -0.89293796, -0.71906966, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.94004244, -0.89293796, -0.71906966, ...,  0.        ,\n         0.        ,  0.        ],\n       [-1.4221154 , -1.1857045 , -1.2149798 , ...,  0.        ,\n         0.        ,  0.        ]], dtype=float32)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations_a_after_training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T19:16:35.359237800Z",
     "start_time": "2023-10-11T19:16:35.293264900Z"
    }
   },
   "id": "61175216df86d374"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "92b97ff035ba1210"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
